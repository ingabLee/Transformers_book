{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2LtLB7Glr4+/9wDhsZOq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingabLee/Transformers_book/blob/main/Transformers1_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTUlm7tYZbKY"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "zsMWG558aOIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O2y6KcV0BanU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "sentiment = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "phtDOuJjbWeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment.model"
      ],
      "metadata": {
        "id": "oNwK144CcgNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment([\"I like olympic games as it's very exciting.\"]))\n",
        "print(sentiment([\"I'm against to hold Olympic game in Tokyo in terms of preventing the covid19 to be spread.\"]))\n"
      ],
      "metadata": {
        "id": "d8qVjF71ctdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline('question-answering')\n",
        "\n",
        "olympic_wiki_text = \"\"\"\n",
        "The 2020 Summer Olympics,[c] officially the Games of the XXXII Olympiad[d] and officially branded as Tokyo 2020,[e] was an international multi-sport event that was held from 23 July to 8 August 2021 in Tokyo, Japan, with some of the preliminary sporting events beginning on 21 July 2021. Tokyo was selected as the host city during the 125th IOC Session in Buenos Aires, Argentina on 7 September 2013.[3]\n",
        "\n",
        "Originally scheduled to take place from 24 July to 9 August 2020, the Tokyo Games were postponed until 2021 on 24 March 2020 as a result of the global COVID-19 pandemic, the first such instance in the history of the Olympic Games (some previous editions had been cancelled but not rescheduled).[4][5] However, the Tokyo 2020 branding was retained for marketing purposes.[6] The events were largely held behind closed doors with no public spectators permitted due to the declaration of a state of emergency in the Greater Tokyo Area in response to the pandemic, the only Olympic Games to be held without official spectators.[f] As a consequence of the postponement and the additional challenges caused by the pandemic, the 2020 Games were the most costly ever, with a total expenditure of over $20 billion.[8]\n",
        "\n",
        "The 2020 Games were the fourth Olympics to be held in Japan, following the 1964 Summer Olympics (Tokyo), the 1972 Winter Olympics (Sapporo), and the 1998 Winter Olympics (Nagano). Tokyo became the first city in Asia to hold the Summer Olympic Games twice.[g] The 2020 Games were the second of three consecutive Olympics to be held in East Asia, following the 2018 Winter Olympics in Pyeongchang, South Korea and preceding the 2022 Winter Olympics in Beijing, China. Because of the one-year postponement, Tokyo 2020 is the only Olympic Games to have taken place in an odd-numbered year.[10]\n",
        "\"\"\"\n",
        "\n",
        "print(qa(question=\"What cause Tokyo Olympic postponed?\", context=olympic_wiki_text))"
      ],
      "metadata": {
        "id": "g_FChoxNdeT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.model"
      ],
      "metadata": {
        "id": "pzD1-FxretQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "--4E9z_XfdSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torchtext==0.15.2\n",
        "!pip install portalocker==2.7.0\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "cSRKOkS6iNd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "# 출력 결과를 고정하기 위해\n",
        "import random\n",
        "random.seed(6)\n",
        "\n",
        "# train_iter를 리스트 타입으로 변경\n",
        "train_list = list(train_iter)\n",
        "test_list = list(test_iter)\n",
        "\n",
        "# 각기 1000개씩 random sampling\n",
        "train_list_small = random.sample(train_list, 1000)\n",
        "test_list_small = random.sample(test_list, 1000)\n",
        "\n",
        "# 각 변수에 담긴 인덱스 0의 내용 화면 출력\n",
        "print(train_list_small[0])\n",
        "print(test_list_small[0])"
      ],
      "metadata": {
        "id": "RaY2jroqjZJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_text, train_label 컨테이너 생성\n",
        "# 아래 반복문에서 생성된 결과를 담는다.\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "\n",
        "#for 반복문\n",
        "# train_list_small에 담긴 튜플쌍 원소를 변수명 label, test부여하여 순서대로 축출\n",
        "for label, text in train_list_small:\n",
        "  # IMDB 데이터의 기존 레이블 2를 1로 변경, 기존 레이블 1을 0으로 변경.\n",
        "  train_labels.append(1 if label == 2 else 0)\n",
        "  train_texts.append(text)\n",
        "\n",
        "# test_list_small도 동일하게 처리\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for label, text in test_list_small:\n",
        "  test_labels.append(1 if label==2 else 0)\n",
        "  test_texts.append(text)\n",
        "\n",
        "# 각 변수에 담긴 첫번째 원소 출력\n",
        "print(train_texts[0])\n",
        "print(train_labels[0])\n",
        "print(test_texts[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "GGGqup0wmZ9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2,random_state=3)\n",
        "\n",
        "print(len(train_texts))\n",
        "print(len(train_labels))\n",
        "print(len(val_texts))\n",
        "print(len(val_labels))"
      ],
      "metadata": {
        "id": "EYN7I_QXqFV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# colab 런타임이 끊어지는 경우에만 재 실행.\n",
        "# !pip install transformers\n",
        "\n",
        "# distilbert-base-uncased 모델에서 tokenizer 불러오기\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "rV_Mds4WqYiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer execute\n",
        "# truncation=True -> 모델의 default max_length를 넘는 입력부분은 더이상 받지않고 절단한다는 의미\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "# 0번째 입력문의 5번째 토큰까지 input_ids출력\n",
        "print(train_encodings[\"input_ids\"][0][:5])\n",
        "\n",
        "#위의 결과를 다시 디코딩해서 출력\n",
        "print(tokenizer.decode(train_encodings[\"input_ids\"][0][:5]))\n"
      ],
      "metadata": {
        "id": "zjYxyzrsv22x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Dataset 클래스를 상속하는 IMDB class정의\n",
        "class IMdbDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  # contructor\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  #\n",
        "  def __getitem__(self, idx):\n",
        "    # self.encoding에 담긴 키(key)와 키값(value)를 items()로 축출\n",
        "    # 이 값을 key와 val 변수에 담아 새로운 키와 키값(torch.tensor(val[idx]))을 갖는 딕셔너리 생성\n",
        "\n",
        "    # 딕셔너리{\"key1 : value1\", ...} 형태를 가지는 데이터 구조.\n",
        "    # val[idx]에 담긴 데이터를 torch.tensor()을 통해 텐셔화.\n",
        "    item = {key:torch.tensor(val[idx]) for key, val in self.encodings.items() }\n",
        "\n",
        "    # tensor화\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  #\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "train_dataset = IMdbDataset(train_encodings, train_labels)\n",
        "val_dataset = IMdbDataset(val_encodings, val_labels)\n",
        "test_dataset = IMdbDataset(test_encodings, test_labels)\n",
        "\n",
        "for i in train_dataset:\n",
        "  print(i)\n",
        "  break\n"
      ],
      "metadata": {
        "id": "7jZSjSA6xtCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cRUBJh7JFLn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}