{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOoS3hDeWph6lf//P2moGHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingabLee/Transformers_book/blob/main/Transformer_09_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT4oP6-RDlPG",
        "outputId": "58836278-c677-486b-d150-6d11f20ecabb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.1.0\n",
            "    Uninstalling numpy-2.1.0:\n",
            "      Successfully uninstalled numpy-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.0 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers==4.30.0\n",
        "#!pip install torchtext==0.15.2\n",
        "#!pip install portalocker==2.7.0\n",
        "#!pip install accelerate -U\n",
        "!pip install numpy==1.26.4  # 아래의 2.4.0이 문제없으면 굳이 업데이트 안해도 될듯..\n",
        "#!pip install torch==2.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "\n",
        "# 출력 결과를 고정하기 위해\n",
        "import random\n",
        "random.seed(6)\n",
        "\n",
        "# train_iter를 리스트 타입으로 변경\n",
        "train_list = list(train_iter)\n",
        "test_list = list(test_iter)\n",
        "\n",
        "# 각기 1000개씩 random sampling\n",
        "train_list_small = random.sample(train_list, 1000)\n",
        "test_list_small = random.sample(test_list, 1000)\n",
        "\n",
        "# 각 변수에 담긴 인덱스 0의 내용 화면 출력\n",
        "print(train_list_small[0])\n",
        "print(test_list_small[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXvDkgeoD6A8",
        "outputId": "a485da16-2ac3-4e2d-a315-6480ab104b6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, \"I LOVED this movie! I am biased seeing as I am a huge Disney fan, but I really enjoyed myself. The action takes off running in the beginning of the film and just keeps going! This is a bit of a departure for Disney, they don't spend quite as much time on character development (my husband pointed this out)and there are no musical numbers. It is strictly action adventure. I thoroughly enjoyed it and recommend it to anyone who loves Disney, be they young or old.\")\n",
            "(1, 'This was an abysmal show. In short it was about this kid called Doug who guilt-tripped a lot. Seriously he could feel guilty over killing a fly then feeling guilty over feeling guilty for killing the fly and so forth. The animation was grating and unpleasant and the jokes cheap. <br /><br />It aired here in Sweden as a part of the \"Disney time\" show and i remember liking it some what but then i turned 13.<br /><br />I never got why some of the characters were green and purple too. What was up with that? <br /><br />Truly a horrible show. Appareantly it spawned a movie which i\\'ve never seen but i don\\'t have any great expectations for that one either.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_text, train_label 컨테이너 생성\n",
        "# 아래 반복문에서 생성된 결과를 담는다.\n",
        "train_texts = []\n",
        "train_labels = []\n",
        "\n",
        "#for 반복문\n",
        "# train_list_small에 담긴 튜플쌍 원소를 변수명 label, test부여하여 순서대로 축출\n",
        "for label, text in train_list_small:\n",
        "  # IMDB 데이터의 기존 레이블 2를 1로 변경, 기존 레이블 1을 0으로 변경.\n",
        "  train_labels.append(1 if label == 2 else 0)\n",
        "  train_texts.append(text)\n",
        "\n",
        "# test_list_small도 동일하게 처리\n",
        "test_texts = []\n",
        "test_labels = []\n",
        "for label, text in test_list_small:\n",
        "  test_labels.append(1 if label==2 else 0)\n",
        "  test_texts.append(text)\n",
        "\n",
        "# 각 변수에 담긴 첫번째 원소 출력\n",
        "print(train_texts[0])\n",
        "print(train_labels[0])\n",
        "print(test_texts[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "AhqvxIDUD-dN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7419a4-de02-4345-9941-b54985962051"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I LOVED this movie! I am biased seeing as I am a huge Disney fan, but I really enjoyed myself. The action takes off running in the beginning of the film and just keeps going! This is a bit of a departure for Disney, they don't spend quite as much time on character development (my husband pointed this out)and there are no musical numbers. It is strictly action adventure. I thoroughly enjoyed it and recommend it to anyone who loves Disney, be they young or old.\n",
            "1\n",
            "This was an abysmal show. In short it was about this kid called Doug who guilt-tripped a lot. Seriously he could feel guilty over killing a fly then feeling guilty over feeling guilty for killing the fly and so forth. The animation was grating and unpleasant and the jokes cheap. <br /><br />It aired here in Sweden as a part of the \"Disney time\" show and i remember liking it some what but then i turned 13.<br /><br />I never got why some of the characters were green and purple too. What was up with that? <br /><br />Truly a horrible show. Appareantly it spawned a movie which i've never seen but i don't have any great expectations for that one either.\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2,random_state=3)\n",
        "\n",
        "print(len(train_texts))\n",
        "print(len(train_labels))\n",
        "print(len(val_texts))\n",
        "print(len(val_labels))"
      ],
      "metadata": {
        "id": "HXl9XeuDEMeA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3efc7f3-82e2-4118-aba2-d00c1348d2b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "800\n",
            "200\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distilbert-base-uncased 모델에서 tokenizer 불러오기\n",
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "id": "5ujSY8MyER3O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326410f2-068b-4f1d-d7f7-3713df1d1f3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer execute\n",
        "# truncation=True -> 모델의 default max_length를 넘는 입력부분은 더이상 받지않고 절단한다는 의미\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "# 0번째 입력문의 5번째 토큰까지 input_ids출력\n",
        "print(train_encodings[\"input_ids\"][0][:5])\n",
        "\n",
        "#위의 결과를 다시 디코딩해서 출력\n",
        "print(tokenizer.decode(train_encodings[\"input_ids\"][0][:5]))"
      ],
      "metadata": {
        "id": "NiBBfe9yEWx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3faad2d7-0d0c-4523-9586-b59e17ecea4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 4937, 11350, 2038, 2048]\n",
            "[CLS] cat soup has two\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Dataset 클래스를 상속하는 IMDB class정의\n",
        "class IMdbDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  # contructor\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  #\n",
        "  def __getitem__(self, idx):\n",
        "    # self.encoding에 담긴 키(key)와 키값(value)를 items()로 축출\n",
        "    # 이 값을 key와 val 변수에 담아 새로운 키와 키값(torch.tensor(val[idx]))을 갖는 딕셔너리 생성\n",
        "\n",
        "    # 딕셔너리{\"key1 : value1\", ...} 형태를 가지는 데이터 구조.\n",
        "    # val[idx]에 담긴 데이터를 torch.tensor()을 통해 텐셔화.\n",
        "    item = {key:torch.tensor(val[idx]) for key, val in self.encodings.items() }\n",
        "\n",
        "    # tensor화\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  #\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "train_dataset = IMdbDataset(train_encodings, train_labels)\n",
        "val_dataset = IMdbDataset(val_encodings, val_labels)\n",
        "test_dataset = IMdbDataset(test_encodings, test_labels)\n",
        "\n",
        "for i in train_dataset:\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "id": "PU2YWGzmEi9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47115668-d7b7-4a47-89ef-cdbc92f81b6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([  101,  4937, 11350,  2038,  2048,  1000,  7592, 14433,  1000,  1011,\n",
            "         2828, 18401,  2015, 28866,  2075,  2006,  1037, 13576,  4440,  2083,\n",
            "         1996, 25115,  1010,  2073,  2505,  2064,  4148,  1010,  1998,  2515,\n",
            "         1012,  2023,  2568,  1011,  4440,  4691,  4004,  2460,  3594,  2053,\n",
            "        13764,  8649,  1010,  4942, 21532,  2773, 22163,  2612,  1012,  2045,\n",
            "         2003,  2053,  2126,  1997,  7851,  2023, 17183, 14088,  9476,  3272,\n",
            "         2000,  2425,  2017,  2000,  2156,  2009,  2005,  4426,  1012,  1998,\n",
            "         2191,  2469,  2053,  2028,  2104,  2184,  2003,  1999,  1996,  2282,\n",
            "         1012,  4487,  6491,  6633,  5677,  3672,  1998,  2064,  3490, 10264,\n",
            "         2964,  1998, 18186,  1998,  9576,  2854,  1998,  5573,  2331,  1998,\n",
            "         2655,  3560, 27770,  2005,  2500,  2024,  2691,  6991,  1012,  7481,\n",
            "         1012,  3383,  1996,  2087, 13432,  3746,  2003,  2008,  1997,  2019,\n",
            "        10777,  3605,  1997,  2300,  2008,  1996,  8934,  7368,  9880,  2083,\n",
            "         1998,  1999,  1010,  1998,  2036,  4536,  1012,  2021,  2066,  8134,\n",
            "         2673,  2842,  1999,  2023,  2143,  1010,  2008, 10021,  1010, 27263,\n",
            "        17933,  4226, 25347,  2574,  3310,  2000,  1037,  9202,  2203,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(1)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-7-b842a72e2461>\", line 32, in <cell line: 0>\n",
            "    for i in train_dataset:\n",
            "  File \"<ipython-input-7-b842a72e2461>\", line 18, in __getitem__\n",
            "    item = {key:torch.tensor(val[idx]) for key, val in self.encodings.items() }\n",
            "  File \"<ipython-input-7-b842a72e2461>\", line 18, in <dictcomp>\n",
            "    item = {key:torch.tensor(val[idx]) for key, val in self.encodings.items() }\n",
            "<ipython-input-7-b842a72e2461>:18: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  item = {key:torch.tensor(val[idx]) for key, val in self.encodings.items() }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification\n",
        "\n",
        "# load distilbert model.  (need transformers==4.30.0)\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "model"
      ],
      "metadata": {
        "id": "muR1kUQAEp9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1e9bc6-4ff1-4b64-8104-c2e779328d22"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "train_args = TrainingArguments(\n",
        "    output_dir='./result',    # 출력 폴더 설정\n",
        "    num_train_epochs=8,       # training epochs count\n",
        "    per_device_train_batch_size=16, # train mini-batch size\n",
        "    per_device_eval_batch_size=64,  # eval min-batch size\n",
        "    warmup_steps=500,   # learning-rate scheduling warmup step\n",
        "    weight_decay=0.01,  # 가중치 감소 강도\n",
        "    logging_dir='./logs',   #로그 폴더 경로\n",
        "    logging_steps=10\n",
        ")"
      ],
      "metadata": {
        "id": "eTuHO-GXKn7Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# gpu사용이 가능한 경우 tensor타입를 gpu로 전달\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Q64gJIABQWhu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tunning이전에 세입력 문장 극성 판별\n",
        "# tokenizing\n",
        "input_tokens = tokenizer([\"I feel fantasic\",\n",
        "                          \"My life is going something wrong.\",\n",
        "                          \"I have not figured out what the chosen title has to do with the movie.\"],\n",
        "                         truncation=True, padding=True)\n",
        "\n",
        "# input text tokenizing result에 담긴 input_ids를 모델에 투입\n",
        "# 그리고 모델 출력 결과를 gpu로 전송하며 값은 변수 outputs에 저장\n",
        "outputs = model(torch.tensor(input_tokens['input_ids']).to(device))\n",
        "\n",
        "# create label dictionary\n",
        "label_dict = {0:'positvie', 1:'negative'}\n",
        "print(outputs['logits'])\n",
        "\n",
        "\n",
        "# outputs변수에 담긴 logits값을 행단위, 즉, 입력문장 단위로 가장 큰값의 위치(인덱스) 추출\n",
        "# 결과값(인덱스)을 cpu로 넘기고 넘파이 타입으로 변경후, 인덱스에 매칭되는 레이블 출력\n",
        "\n",
        "#print([label_dict[i] for i in torch.argmax(outputs['logits'], axis=1).cpu().numpy()])\n",
        "v = torch.argmax(outputs['logits'], axis=1)\n",
        "print(v)\n",
        "print(v.cpu().numpy())\n",
        "print(torch.__version__)\n",
        "\n",
        "#w = v.detach().numpy()\n",
        "print([label_dict[i] for i in w])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "TWtIirmaSbT1",
        "outputId": "14d5ea04-ac4a-4f5a-a2b1-9b484af30c85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0345, 0.1502],\n",
            "        [0.0580, 0.0974],\n",
            "        [0.0599, 0.1616]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
            "tensor([1, 1, 1], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Numpy is not available",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ef13c8d8be97>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# maybe 5minute\n",
        "\n",
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,      # pretrain model instance\n",
        "    args = training_args, # transformer.Arguments define hyper parameter\n",
        "    train_dataset = train_dataset,  # train data set\n",
        "    eval_dataset = val_dataset    # evaluation data set\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "yY7iv1rJUmIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after fine-tunning. then try again three text\n",
        "\n",
        "input_tokens = tokenizer([\"I feel fantasic\",\n",
        "                          \"My life is going something wrong.\",\n",
        "                          \"I have not figured out what the chosen title has to do with the movie.\"],\n",
        "                         truncation=True, padding=True)\n",
        "\n",
        "# input text tokenizing result에 담긴 input_ids를 모델에 투입\n",
        "# 그리고 모델 출력 결과를 gpu로 전송하며 값은 변수 outputs에 저장\n",
        "outputs = model(torch.tensor(input_tokens['input_ids']).to(device))\n",
        "\n",
        "# create label dictionary\n",
        "label_dict = {0:'positvie', 1:'negative'}\n",
        "print(outputs['logits'])\n",
        "\n",
        "\n",
        "# outputs변수에 담긴 logits값을 행단위, 즉, 입력문장 단위로 가장 큰값의 위치(인덱스) 추출\n",
        "# 결과값(인덱스)을 cpu로 넘기고 넘파이 타입으로 변경후, 인덱스에 매칭되는 레이블 출력\n",
        "\n",
        "#print([label_dict[i] for i in torch.argmax(outputs['logits'], axis=1).cpu().numpy()])\n",
        "v = torch.argmax(outputs['logits'], axis=1).detach().numpy()\n",
        "print([label_dict[i] for i in v])"
      ],
      "metadata": {
        "id": "_KWJAHbGcoVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}